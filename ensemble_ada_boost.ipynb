{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/fnilvu/Documents/Project Medaka/API Ikan/javanicus.jpeg: 352x640 1 O.javanicus, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /home/fnilvu/Documents/Project Medaka/API Ikan/javanicus.jpeg: 352x640 1 O.javanicus, 25.7ms\n",
      "Speed: 1.5ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /home/fnilvu/Documents/Project Medaka/API Ikan/javanicus.jpeg: 352x640 1 O.javanicus, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /home/fnilvu/Documents/Project Medaka/API Ikan/javanicus.jpeg: 352x640 1 O.javanicus, 25.6ms\n",
      "Speed: 2.5ms preprocess, 25.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /home/fnilvu/Documents/Project Medaka/API Ikan/javanicus.jpeg: 352x640 1 O.javanicus, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Detection 1:\n",
      "  Box: [61.38822937011719, 58.2691764831543, 245.17117309570312, 122.53103637695312]\n",
      "  Score: 0.6479\n",
      "  Class: 1.0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# Load the trained models\n",
    "model_1 = YOLO('best_model1.pt')\n",
    "model_2 = YOLO('best_model2.pt')\n",
    "model_3 = YOLO('best_model3.pt')\n",
    "model_4 = YOLO('best_model4.pt')\n",
    "model_5 = YOLO('best_model5.pt')\n",
    "\n",
    "# Function to calculate the model weight (alpha) based on the error rate\n",
    "def calculate_model_weight(error_rate):\n",
    "    return 0.5 * math.log((1 - error_rate) / error_rate)\n",
    "\n",
    "# Example: Replace these with your actual error rates for each model\n",
    "error_rate_1 = 0.2  # Example error rate for best_model1.pt\n",
    "error_rate_2 = 0.2 # Example error rate for best_model2.pt\n",
    "error_rate_3 = 0.2 # Example error rate for best_model3.pt\n",
    "error_rate_4 = 0.2 # Example error rate for best_model4.pt\n",
    "error_rate_5 = 0.2 # Example error rate for best_model5.pt\n",
    "\n",
    "# Calculate weights (alphas) for each model\n",
    "alpha_1 = calculate_model_weight(error_rate_1)\n",
    "alpha_2 = calculate_model_weight(error_rate_2)\n",
    "alpha_3 = calculate_model_weight(error_rate_3)\n",
    "alpha_4 = calculate_model_weight(error_rate_4)\n",
    "alpha_5 = calculate_model_weight(error_rate_5)\n",
    "\n",
    "# Ensemble method to combine predictions using AdaBoost-inspired weights\n",
    "def ensemble_adaboost(image_path, models, alphas):\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_classes = []\n",
    "    \n",
    "    for model, alpha in zip(models, alphas):\n",
    "        results = model.predict(image_path, conf=0.25)  # Adjust confidence threshold if needed\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            all_boxes.append(boxes.xyxy)\n",
    "            all_scores.append(boxes.conf * alpha)  # Apply alpha weight to confidence scores\n",
    "            all_classes.append(boxes.cls)\n",
    "    \n",
    "    if all_boxes:\n",
    "        # Concatenate all predictions\n",
    "        boxes_tensor = torch.cat(all_boxes)\n",
    "        scores_tensor = torch.cat(all_scores)\n",
    "        classes_tensor = torch.cat(all_classes)\n",
    "\n",
    "        # Perform NMS\n",
    "        nms_indices = torch.ops.torchvision.nms(boxes_tensor, scores_tensor, 0.5)\n",
    "        \n",
    "        # Create final predictions\n",
    "        final_boxes = boxes_tensor[nms_indices]\n",
    "        final_scores = scores_tensor[nms_indices]\n",
    "        final_classes = classes_tensor[nms_indices]\n",
    "        \n",
    "        return list(zip(final_boxes, final_scores, final_classes))\n",
    "    \n",
    "    return []\n",
    "\n",
    "# Combine predictions using the ensemble method\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "alphas = [alpha_1, alpha_2, alpha_3, alpha_4, alpha_5]\n",
    "\n",
    "# Example image to test the ensemble model\n",
    "image_path = 'javanicus.jpeg'\n",
    "final_predictions = ensemble_adaboost(image_path, models, alphas)\n",
    "\n",
    "# Print or visualize the final predictions\n",
    "for i, (box, score, cls) in enumerate(final_predictions):\n",
    "    print(f\"Detection {i+1}:\")\n",
    "    print(f\"  Box: {box.tolist()}\")\n",
    "    print(f\"  Score: {score.item():.4f}\")\n",
    "    print(f\"  Class: {cls.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble configuration saved to ensemble_model_config.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Save the ensemble configuration\n",
    "def save_ensemble_config(model_paths, alphas, file_path='ensemble_model_config.pt'):\n",
    "    \"\"\"\n",
    "    Save the ensemble model configuration to a file.\n",
    "\n",
    "    Args:\n",
    "    - model_paths (list of str): List of paths to the model files.\n",
    "    - alphas (list of float): List of alpha weights for each model.\n",
    "    - file_path (str): Path where the ensemble configuration will be saved.\n",
    "    \"\"\"\n",
    "    ensemble_config = {\n",
    "        'model_paths': model_paths,\n",
    "        'alphas': alphas\n",
    "    }\n",
    "\n",
    "    torch.save(ensemble_config, file_path)\n",
    "    print(f\"Ensemble configuration saved to {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "model_paths = ['best_model1.pt', 'best_model2.pt', 'best_model3.pt', 'best_model4.pt', 'best_model5.pt']\n",
    "alphas = [alpha_1, alpha_2, alpha_3, alpha_4, alpha_5]\n",
    "save_ensemble_config(model_paths, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/fnilvu/Documents/Project Medaka/API Ikan/javanicus.jpeg: 352x640 1 O.javanicus, 126.0ms\n",
      "Speed: 50.8ms preprocess, 126.0ms inference, 64.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Detection 1:\n",
      "  Box: [59.406219482421875, 59.04910659790039, 246.71923828125, 122.02272033691406]\n",
      "  Score: 0.4339\n",
      "  Class: 1.0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO('best_model1.pt')\n",
    "\n",
    "# Example weight for the model\n",
    "weight = 0.5  # Adjust this weight based on your requirement\n",
    "\n",
    "# Function to apply weight to confidence scores\n",
    "def apply_weight_to_scores(results, weight):\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_classes = []\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        all_boxes.append(boxes.xyxy)\n",
    "        all_scores.append(boxes.conf * weight)  # Apply weight to confidence scores\n",
    "        all_classes.append(boxes.cls)\n",
    "    \n",
    "    if all_boxes:\n",
    "        # Concatenate all predictions\n",
    "        boxes_tensor = torch.cat(all_boxes)\n",
    "        scores_tensor = torch.cat(all_scores)\n",
    "        classes_tensor = torch.cat(all_classes)\n",
    "\n",
    "        # Perform NMS\n",
    "        nms_indices = torch.ops.torchvision.nms(boxes_tensor, scores_tensor, 0.5)\n",
    "        \n",
    "        # Create final predictions\n",
    "        final_boxes = boxes_tensor[nms_indices]\n",
    "        final_scores = scores_tensor[nms_indices]\n",
    "        final_classes = classes_tensor[nms_indices]\n",
    "        \n",
    "        return list(zip(final_boxes, final_scores, final_classes))\n",
    "    \n",
    "    return []\n",
    "\n",
    "# Predict using the single model\n",
    "image_path = 'javanicus.jpeg'\n",
    "results = model.predict(image_path, conf=0.25)  # Adjust confidence threshold if needed\n",
    "\n",
    "# Apply weights to the predictions\n",
    "final_predictions = apply_weight_to_scores(results, weight)\n",
    "\n",
    "# Print or visualize the final predictions\n",
    "for i, (box, score, cls) in enumerate(final_predictions):\n",
    "    print(f\"Detection {i+1}:\")\n",
    "    print(f\"  Box: {box.tolist()}\")\n",
    "    print(f\"  Score: {score.item():.4f}\")\n",
    "    print(f\"  Class: {cls.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the trained YOLO model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mensemble_model_config.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Example weight for the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Adjust this weight based on your requirement\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Project Medaka/API Ikan/venv/lib/python3.11/site-packages/ultralytics/models/yolo/model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Project Medaka/API Ikan/venv/lib/python3.11/site-packages/ultralytics/engine/model.py:143\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Project Medaka/API Ikan/venv/lib/python3.11/site-packages/ultralytics/engine/model.py:295\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    292\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/Project Medaka/API Ikan/venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:857\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    855\u001b[0m ckpt, weight \u001b[38;5;241m=\u001b[39m torch_safe_load(weight)  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m    856\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;66;03m# Model compatibility updates\u001b[39;00m\n\u001b[1;32m    860\u001b[0m model\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m DEFAULT_CFG_KEYS}  \u001b[38;5;66;03m# attach args to model\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO('ensemble_model_config.pt')\n",
    "\n",
    "# Example weight for the model\n",
    "weight = 0.5  # Adjust this weight based on your requirement\n",
    "\n",
    "# Function to apply weight to confidence scores\n",
    "def apply_weight_to_scores(results, weight):\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_classes = []\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        all_boxes.append(boxes.xyxy)\n",
    "        all_scores.append(boxes.conf * weight)  # Apply weight to confidence scores\n",
    "        all_classes.append(boxes.cls)\n",
    "    \n",
    "    if all_boxes:\n",
    "        # Concatenate all predictions\n",
    "        boxes_tensor = torch.cat(all_boxes)\n",
    "        scores_tensor = torch.cat(all_scores)\n",
    "        classes_tensor = torch.cat(all_classes)\n",
    "\n",
    "        # Perform NMS\n",
    "        nms_indices = torch.ops.torchvision.nms(boxes_tensor, scores_tensor, 0.5)\n",
    "        \n",
    "        # Create final predictions\n",
    "        final_boxes = boxes_tensor[nms_indices]\n",
    "        final_scores = scores_tensor[nms_indices]\n",
    "        final_classes = classes_tensor[nms_indices]\n",
    "        \n",
    "        return list(zip(final_boxes, final_scores, final_classes))\n",
    "    \n",
    "    return []\n",
    "\n",
    "# Predict using the single model\n",
    "image_path = 'javanicus.jpeg'\n",
    "results = model.predict(image_path, conf=0.25)  # Adjust confidence threshold if needed\n",
    "\n",
    "# Apply weights to the predictions\n",
    "final_predictions = apply_weight_to_scores(results, weight)\n",
    "\n",
    "# Print or visualize the final predictions\n",
    "for i, (box, score, cls) in enumerate(final_predictions):\n",
    "    print(f\"Detection {i+1}:\")\n",
    "    print(f\"  Box: {box.tolist()}\")\n",
    "    print(f\"  Score: {score.item():.4f}\")\n",
    "    print(f\"  Class: {cls.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
